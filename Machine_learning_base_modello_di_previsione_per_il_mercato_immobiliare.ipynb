{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPnzaQhbgOd3xfyoZtUwSLh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/albertoliuzzo/progetti_AI/blob/main/Machine_learning_base_modello_di_previsione_per_il_mercato_immobiliare.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59PjXS8Xveei"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_squared_error\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
        "\n",
        "df=pd.read_csv(\"housing.csv\") #carico il dataset\n",
        "\n",
        "#DATA PREPROCESSING\n",
        "\n",
        "df.isna().sum()  #verifico la presenza di valori nulli\n",
        "\n",
        "corr_matrix = df.corr() # calcolo la matrice di correlazione e la visualizzo, per selezione delle feature (eliminare feature non rilevanti o altamente correlate tra loro)\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", linewidths=0.5)\n",
        "plt.title(\"Matrice di Correlazione tra le Feature\")\n",
        "plt.show()\n",
        "\n",
        "# verifica ed eliminazione outliers\n",
        "Q1 = df[\"price\"].quantile(0.20) #metodo IQR\n",
        "Q3 = df[\"price\"].quantile(0.80)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "new_df = df[(df[\"price\"] < upper_bound)] #nuovo dataset senza outliers\n",
        "\n",
        "X=new_df.drop([\"price\",\"hotwaterheating\",\"furnishingstatus\",\"basement\",\"guestroom\",\"mainroad\"], axis=1) #creo il dataset X senza il target e le feature non rilevanti\n",
        "y=new_df[\"price\"] #creo il target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1) #divido in dataset di training e dataset di test\n",
        "\n",
        "ct = ColumnTransformer(  #creo l'istanza che standardizza le variabili continue e ordinali (escludendo le binarie)\n",
        "    transformers=[('scaler', StandardScaler(), [\"area\",\"bedrooms\", \"bathrooms\", \"stories\", \"parking\"] ) ],\n",
        "    remainder = \"passthrough\")\n",
        "\n",
        "X_train = ct.fit_transform(X_train)  #fitto e trasformo il modello ottenendo i dataset con le feature standardizzate\n",
        "X_test = ct.transform(X_test)\n",
        "\n",
        "#CREAZIONE DEI MODELLI\n",
        "\n",
        "param_grid = {\"alpha\": np.logspace(-4, 1, 30)} #creo 30 valori del parametro alpha che vanno da 10^(-4) a 10^1\n",
        "\n",
        "#utilizzo la GridSearchCV per trovare i migliori valori di alpha che ottimizzino il coefficiente di determinazione l'MSE\n",
        "grid_search_R = GridSearchCV(Ridge(), param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "grid_search_R.fit(X_train, y_train)\n",
        "print(\"Miglior valore di alpha per Ridge:\", grid_search_R.best_params_['alpha'])\n",
        "\n",
        "grid_search_L = GridSearchCV(Lasso(), param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "grid_search_L.fit(X_train, y_train)\n",
        "print(\"Miglior valore di alpha per Lasso:\", grid_search_L.best_params_['alpha'])\n",
        "\n",
        "grid_search_El = GridSearchCV(ElasticNet(), param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "grid_search_El.fit(X_train, y_train)\n",
        "print(\"Miglior valore di alpha per ElasticNet:\", grid_search_El.best_params_['alpha'])\n",
        "\n",
        "#creo i modelli di Regression Ridge, Lasso ed ElasticNet (con gli alpha ottenuti)\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import ElasticNet\n",
        "\n",
        "model_R = Ridge(alpha=3.039195382313201)\n",
        "model_R.fit(X_train, y_train)\n",
        "\n",
        "model_L = Lasso(alpha=0.0001)\n",
        "model_L.fit(X_train, y_train)\n",
        "\n",
        "model_E = ElasticNet(alpha=0.01743328822199989)\n",
        "model_E.fit(X_train, y_train)\n",
        "\n",
        "#VALUTAZIONE DEI MODELLI\n",
        "\n",
        "#valuto i 3 modelli sul set di training tramite cross validation\n",
        "score_R = cross_val_score(model_R, X_train, y_train, cv=5, scoring=\"r2\").mean()  #calcolo il coefficiente di determinazione sul set di training, come media degli R2 dei vari folds\n",
        "score_L = cross_val_score(model_L, X_train, y_train, cv=5, scoring=\"r2\").mean()\n",
        "score_E = cross_val_score(model_E, X_train, y_train, cv=5, scoring=\"r2\").mean()\n",
        "\n",
        "score_R_test = model_R.score(X_test, y_test)  #calcolo il coefficiente di determinazione sul set di test, grazie alla funzione score()\n",
        "score_L_test = model_L.score(X_test, y_test)\n",
        "score_E_test = model_E.score(X_test, y_test)\n",
        "\n",
        "print(f\"Ridge Regression - Train R2: {score_R:.3f}, Test R2: {score_R_test:.3f}\") #stampa dei risultati\n",
        "print(f\"Lasso Regression - Train R2: {score_L:.3f}, Test R2: {score_L_test:.3f}\")\n",
        "print(f\"Elastic Net - Train R2: {score_E:.3f}, Test R2: {score_E_test:.3f}\")\n",
        "#Ridge Regression - Train R2: 0.625, Test R2: 0.618\n",
        "#Lasso Regression - Train R2: 0.625, Test R2: 0.620\n",
        "#Elastic Net - Train R2: 0.625, Test R2: 0.617\n",
        "\n",
        "#MSE\n",
        "y_train_pred_R = model_R.predict(X_train)  #calcolo le predizioni dei modelli rispetto al set di training\n",
        "y_train_pred_L = model_L.predict(X_train)\n",
        "y_train_pred_E = model_E.predict(X_train)\n",
        "\n",
        "y_test_pred_R = model_R.predict(X_test)  #calcolo le predizioni dei modelli rispetto al set di test\n",
        "y_test_pred_L = model_L.predict(X_test)\n",
        "y_test_pred_E = model_E.predict(X_test)\n",
        "\n",
        "mse_train_R = mean_squared_error(y_train, y_train_pred_R)  #calcolo l'mse sul set di training\n",
        "mse_train_L = mean_squared_error(y_train, y_train_pred_L)\n",
        "mse_train_E = mean_squared_error(y_train, y_train_pred_E)\n",
        "\n",
        "mse_test_R = mean_squared_error(y_test, y_test_pred_R) #calcolo l'mse sul set di test\n",
        "mse_test_L = mean_squared_error(y_test, y_test_pred_L)\n",
        "mse_test_E = mean_squared_error(y_test, y_test_pred_E)\n",
        "\n",
        "print(f\"Ridge Regression - Train MSE: {mse_train_R:.2f}, Test MSE: {mse_test_R:.2f}\") #stampa dei risultati\n",
        "print(f\"Lasso Regression - Train MSE: {mse_train_L:.2f}, Test MSE: {mse_test_L:.2f}\")\n",
        "print(f\"Elastic Net - Train MSE: {mse_train_E:.2f}, Test MSE: {mse_test_E:.2f}\")\n",
        "#Ridge Regression - Train MSE: 1189968293814.19, Test MSE: 1605549997423.95\n",
        "#Lasso Regression - Train MSE: 1189713915417.60, Test MSE: 1597626583200.85\n",
        "#Elastic Net - Train MSE: 1190105262926.58, Test MSE: 1607541751610.49\n",
        "\n",
        "#calcolo dei coefficienti non nulli\n",
        "non_zero_ridge = np.count_nonzero(model_R.coef_)\n",
        "non_zero_lasso = np.count_nonzero(model_L.coef_)\n",
        "non_zero_elastic = np.count_nonzero(model_E.coef_)\n",
        "\n",
        "print(f\"Numero di coefficienti non nulli:\") #stampa dei risultati\n",
        "print(f\"Ridge Regression: {non_zero_ridge}\")\n",
        "print(f\"Lasso Regression: {non_zero_lasso}\")\n",
        "print(f\"Elastic Net: {non_zero_elastic}\")\n",
        "\n",
        "#Numero di coefficienti non nulli:\n",
        "#Ridge Regression: 7\n",
        "#Lasso Regression: 7\n",
        "#Elastic Net: 7\n",
        "\n",
        "#confronto dei 3 modelli con grafico a barre\n",
        "mse_results = pd.DataFrame({   # creo un dataframe con i valori degli MSE per il confronto tra i modelli\n",
        "    \"Modelli\": [\"Ridge\", \"Lasso\", \"ElasticNet\"],\n",
        "    \"MSE Train\": [mse_train_R, mse_train_L, mse_train_E],\n",
        "    \"MSE Test\": [mse_test_R, mse_test_L, mse_test_E]\n",
        "})\n",
        "\n",
        "# visualizzazione degli MSE con un grafico a barre\n",
        "plt.figure(figsize=(10,6))\n",
        "mse_results.set_index(\"Modelli\").plot(kind=\"bar\", figsize=(10,6), alpha=0.8)\n",
        "plt.title(\"Confronto degli MSE tra i modelli\")\n",
        "plt.ylabel(\"Mean Squared Error\")\n",
        "plt.xticks(rotation=0)\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "#Visualizzazione della distribuzione dei residui per valutare l'adeguatezza del modello.\n",
        "\n",
        "# calcolo dei residui (differenza tra valori reali e predetti)\n",
        "residuals_R = y_test - y_test_pred_R\n",
        "residuals_L = y_test - y_test_pred_L\n",
        "residuals_E = y_test - y_test_pred_E\n",
        "\n",
        "# visualizzazione della distribuzione dei residui per ciascun modello\n",
        "plt.figure(figsize=(15,5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "sns.histplot(residuals_R, bins=50, kde=True, color=\"blue\")\n",
        "plt.title(\"Distribuzione dei residui - Ridge\")\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "sns.histplot(residuals_L, bins=40, kde=True, color=\"red\")\n",
        "plt.title(\"Distribuzione dei residui - Lasso\")\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "sns.histplot(residuals_E, bins=50, kde=True, color=\"green\")\n",
        "plt.title(\"Distribuzione dei residui - Elastic Net\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Visualizzazione dell'andamento dei coefficienti dei modelli rispetto ai parametri di regolarizzazione\n",
        "\n",
        "alphas = np.logspace(-4, 4, 30)  # creo 30 valori per alpha da 0.0001 a 10000\n",
        "\n",
        "# liste per memorizzare i coefficienti\n",
        "ridge_coeff = []\n",
        "lasso_coeff = []\n",
        "elastic_coeff = []\n",
        "\n",
        "# ciclo for per testare diversi alpha\n",
        "for alpha in alphas:\n",
        "    model_R = Ridge(alpha=alpha)\n",
        "    model_L = Lasso(alpha=alpha)\n",
        "    model_E = ElasticNet(alpha=alpha)\n",
        "\n",
        "    model_R.fit(X_train, y_train)\n",
        "    model_L.fit(X_train, y_train)\n",
        "    model_E.fit(X_train, y_train)\n",
        "\n",
        "    ridge_coeff.append(model_R.coef_)\n",
        "    lasso_coeff.append(model_L.coef_)\n",
        "    elastic_coeff.append(model_E.coef_)\n",
        "\n",
        "# conversione in array numpy\n",
        "ridge_coeff = np.array(ridge_coefs)\n",
        "lasso_coeff = np.array(lasso_coefs)\n",
        "elastic_coeff = np.array(elastic_coefs)\n",
        "\n",
        "# grafico per visualizzare l'andamento dei coefficienti in Ridge\n",
        "plt.figure(figsize=(10,6))\n",
        "for i in range(ridge_coeff.shape[1]):\n",
        "    plt.plot(alphas, ridge_coeff[:, i], label=f'Feature {i+1}')\n",
        "plt.xscale(\"log\")\n",
        "plt.xlabel(\"Alpha (Lambda)\")\n",
        "plt.ylabel(\"Valore dei Coefficienti\")\n",
        "plt.title(\"Andamento dei coefficienti in Ridge Regression\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# grafico per Lasso\n",
        "plt.figure(figsize=(10,6))\n",
        "for i in range(lasso_coeff.shape[1]):\n",
        "    plt.plot(alphas, lasso_coeff[:, i], label=f'Feature {i+1}')\n",
        "plt.xscale(\"log\")\n",
        "plt.xlabel(\"Alpha (Lambda)\")\n",
        "plt.ylabel(\"Valore dei Coefficienti\")\n",
        "plt.title(\"Andamento dei coefficienti in Lasso Regression\")\n",
        "plt.legend(loc=\"best\", bbox_to_anchor=(1,1))\n",
        "plt.show()\n",
        "\n",
        "# grafico per ElasticNet\n",
        "plt.figure(figsize=(10,6))\n",
        "for i in range(elastic_coeff.shape[1]):\n",
        "    plt.plot(alphas, elastic_coeff[:, i], label=f'Feature {i+1}')\n",
        "plt.xscale(\"log\")\n",
        "plt.xlabel(\"Alpha (Lambda)\")\n",
        "plt.ylabel(\"Valore dei Coefficienti\")\n",
        "plt.title(\"Andamento dei coefficienti in Elastic Net\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ]
}